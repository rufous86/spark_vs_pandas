# Pyspark. Анализ больших данных, когда Pandas не достаточно

Pandas is one of the most used open-source Python libraries to work with Structured tabular data for analysis. Pandas library is heavily used for Data Analytics, Machine learning, data science projects, and many more.  

Pandas can load the data by reading CSV, JSON, SQL, many other formats and creates a DataFrame which is a structured object containing rows and columns (similar to SQL table).

It doesn’t support distributed processing hence you would always need to increase the resources when you need additional horsepower to support your growing data.Pandas DataFrame’s are mutable and are not lazy, statistical functions are applied on each column by default.  

In very simple words Pandas run operations on a single machine whereas PySpark runs on multiple machines. If you are working on a Machine Learning application where you are dealing with larger datasets, PySpark is a best fit which could processes operations many times(100x) faster than Pandas.  

PySpark is very well used in Data Science and Machine Learning community as there are many widely used data science libraries written in Python including NumPy, TensorFlow also used due to their efficient processing of large datasets. PySpark has been used by many organizations like Walmart, Trivago, Sanofi, Runtastic, and many more.

PySpark is a Spark library written in Python to run Python applications using Apache Spark capabilities. Using PySpark we can run applications parallelly on the distributed cluster (multiple nodes) or even on a single node.

Apache Spark is an analytical processing engine for large scale powerful distributed data processing and machine learning applications.

    Pandas - одна из наиболее используемых библиотек Python с открытым исходным кодом для работы со структурированными табличными данными для анализа. Библиотека Pandas активно используется для аналитики данных, машинного обучения, проектов в области науки о данных и многих других.

    Pandas может загружать данные путем чтения CSV, JSON, SQL и многих других форматов и создает DataFrame, который представляет собой структурированный объект, содержащий строки и столбцы (аналогично таблице SQL).

    Он не поддерживает распределенную обработку, поэтому вам всегда придется увеличивать ресурсы, когда вам понадобится дополнительная мощность для поддержки растущих данных. Pandas DataFrame's являются изменяемыми и не ленивыми, статистические функции применяются к каждому столбцу по умолчанию.

    Проще говоря, Pandas выполняет операции на одной машине, в то время как PySpark работает на нескольких машинах. Если вы работаете над приложением машинного обучения, где вы имеете дело с большими наборами данных, PySpark является лучшим вариантом, который может обрабатывать операции во много раз (100x) быстрее, чем Pandas.

    PySpark очень хорошо используется в сообществе Data Science и Machine Learning, так как существует множество широко используемых библиотек Data Science, написанных на Python, включая NumPy, TensorFlow, которые также используются из-за их эффективной обработки больших массивов данных. PySpark используется многими организациями, такими как Walmart, Trivago, Sanofi, Runtastic и многими другими.

    PySpark - это библиотека Spark, написанная на языке Python для запуска приложений Python с использованием возможностей Apache Spark. Используя PySpark, мы можем запускать приложения параллельно на распределенном кластере (несколько узлов) или даже на одном узле.

    Apache Spark - это аналитический процессор для крупномасштабной мощной распределенной обработки данных и приложений машинного обучения.

    Переведено с помощью www.DeepL.com/Translator (бесплатная версия)
